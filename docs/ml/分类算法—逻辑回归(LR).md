# [LR回归(Logistic Regression)]()
## [Logistic 回归 概述]()
Logistic回归 或者叫逻辑回归 虽然名字有回归，但是它是用来做分类的。其主要思想是: 根据现有数据对分类边界线(Decision Boundary)建立回归公式，以此进行分类。

[何为回归呢?]()
假设现在有一些数据点，我们用一条直线对这些点进行拟合（这条直线称为最佳拟合直线），这个拟合的过程就叫做回归。进而可以得到对这些点的拟合直线方程，

那么我们根据这个回归方程，怎么进行分类呢？
我们需要一种函数：$\color{Orange}{能接受所有的输入，然后返回预测出类别。}$例如，在两个类的情况下，上述函数输出 0 或 1.或许你之前接触过具有这种性质的函数，该函数称为 海维塞得阶跃函数(Heaviside step function)，或者直接称为 单位阶跃函数。然而，海维塞得阶跃函数的问题在于: 该函数在跳跃点上从 0 瞬间跳跃到 1，这个瞬间跳跃过程有时很难处理。

幸好，另一个函数也有类似的性质（可以输出 0 或者 1 的性质），且数学上更易处理，这就是 Sigmoid 函数。 Sigmoid 函数具体的计
海维塞得阶跃函数(Heaviside step function):
$$ 
H(n)= \begin{cases} 0, & \text {n $\lt$ 0;} \\ 1, & \text{n $\geq$ 0;} \end{cases} $$
Sigmoid 函数:
$$
\sigma(z)=\frac{1}{1+e^{-z}}
$$
![!\[\](../image/lr1.png)](../image/lr1.png)
为了实现 Logistic 回归分类器，我们可以在每个特征上都乘以一个回归系数（如下公式所示），然后把所有结果值相加，将这个总和代入 Sigmoid 函数中，进而得到一个范围在 0~1 之间的数值。任何大于 0.5 的数据被分入 1 类，小于 0.5 即被归入 0 类。所以，Logistic 回归也是一种概率估计，比如这里Sigmoid 函数得出的值为0.5，可以理解为给定数据和参数，数据被分入 1 类的概率为0.5。


Sigmoid 函数的输入记为 z ，由下面公式得到:
$$
z = w_{0}x_{0} + w_{1}x_{1} + w_{2}x_{2} + ...+ w_{n}x_{n}
$$

[如何求解回归系数呢?]()
参数估计常用方法：[梯度上升和梯度下降](参数估计—梯度上升和梯度下降.md)、[最小二乘法](参数估计—最小二乘法.md)、[极大似然估计](参数估计—极大似然估计.md
)

## [算法实现]（）
