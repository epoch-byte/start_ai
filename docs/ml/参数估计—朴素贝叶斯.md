# [贝叶斯估计(Bayes)]()
## [前言]()
判别式模型和生成式模型是机器学习中两种不同的建模方法，它们在处理数据、构建模型以及实现目标上有着不同的理念和方法。下面是对这两者的详细解释。

### 判别式模型（Discriminative Model）
#### 定义
判别式模型关注的是直接学习输入数据𝑋与输出标签𝑌之间的映射关系，即直接学习条件概率P(Y∣X)。它通过判别边界将不同类别区分开来，通常用于分类和回归问题。
#### 特点
- 关注条件概率：判别式模型直接建模条件概率P(Y∣X)，忽略了输入数据的生成过程。
- 目标：通过优化损失函数，找到最能区分不同类别的决策边界。
- 优势：通常在分类精度上表现较好，特别是在高维数据和复杂模型中。由于不需要建模数据的生成过程，模型训练往往更高效。

#### 常见的判别式模型
- 逻辑回归（Logistic Regression）：线性分类模型，直接估计P(Y∣X)。
- 支持向量机（SVM）：通过寻找最大化类别间隔的超平面进行分类。
- 神经网络（Neural Networks）：通过多层非线性变换进行复杂的映射和分类。
- 条件随机场（CRF）：用于序列标注问题，通过条件概率建模序列数据。
### 生成式模型（Generative Model）
#### 定义
生成式模型关注的是学习输入数据𝑋和输出标签𝑌的联合概率分布P(X,Y)，即通过建模数据的生成过程来推导出条件概率P(Y∣X)。
#### 特点
- 关注联合概率：生成式模型首先学习联合概率P(X,Y)，然后通过贝叶斯公式$P(Y∣X)=\frac {P(X)}{P(X,Y)}$,计算条件概率。
- 目标：能够生成数据，即不仅能进行分类，还能模拟或生成与观测数据相似的样本。
- 优势：生成式模型通常具有更强的解释性和更好的鲁棒性，因为它们了解数据的生成过程，可以应对缺失数据或噪声数据的情况。
#### 常见的生成式模型
- 朴素贝叶斯（Naive Bayes）：假设特征条件独立，通过贝叶斯定理估计类别。
- 高斯混合模型（GMM）：假设数据由多个高斯分布混合生成，通过期望最大化（EM）算法估计参数。
- 隐马尔可夫模型（HMM）：用于序列数据，通过状态转移和观测生成模型建模。
- 生成对抗网络（GAN）：由生成器和判别器组成，通过对抗训练生成逼真的数据样本。
- 变分自编码器（VAE）：结合生成模型和变分推断，进行数据生成和编码。
### 判别式模型与生成式模型的区别与联系
- 学习目标：
  * 判别式模型：直接学习P(Y∣X)，关注如何有效地分类或回归。
  * 生成式模型：首先学习P(X,Y)，关注数据的生成过程以及从生成过程推导分类或回归。
- 数据要求：
  * 判别式模型：通常需要大量的标注数据，注重分类精度和泛化能力。
  * 生成式模型：能在少量数据上进行有效学习，并能生成新数据，具有更强的解释性。
- 模型应用：
  * 判别式模型：主要用于分类和回归任务，尤其在需要高精度分类的场景下。
  * 生成式模型：除了分类和回归，还能用于数据生成、缺失数据填补、异常检测等任务。
### 总结
判别式模型和生成式模型代表了两种不同的建模思路。判别式模型专注于如何准确分类或预测，而生成式模型则兼顾数据生成和分类的能力。选择哪种模型取决于任务的具体需求，如对分类精度、数据生成能力、模型解释性的侧重不同。
## [朴素贝叶斯原理]()
朴素贝叶斯算法基于贝叶斯定理和特征条件独立假设。
- [贝叶斯定理](docs\math\贝叶斯定理.md)
- 特征条件独立：特征条件独立假设X的n个特征在类确定的条件下都是条件独立的。
大大简化了计算过程，但是因为这个假设太过严格，所以会相应牺牲一定的准确率。这也是为什么称呼为朴素的原因。

## [朴素贝叶斯算法]()

## [朴素贝叶斯法学习与分类算法]()

## [朴素贝叶斯算法小结]()

优点
- 朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。
- 对小规模的数据表现很好，能个处理多分类任务，适合增量式训练，尤其是数据量超出内存时，我们可以一批批的去增量训练。
- 对缺失数据不太敏感，算法也比较简单，常用于文本分类。

缺点
- 朴素贝叶斯模型的特征条件独立假设在实际应用中往往是不成立的。
- 如果样本数据分布不能很好的代表样本空间分布，那先验概率容易测不准。
- 对输入数据的表达形式很敏感。
